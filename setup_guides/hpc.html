<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Getting Started with Pangeo on HPC &#8212; Pangeo  documentation</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/pangeo-style.css?v=0dbad12f" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/example_gallery_styles_patched.css?v=417c3662" />
    <link rel="stylesheet" type="text/css" href="../_static/pangeo-main-site-custom.css?v=91edfa83" />
    <script src="../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=30646c52"></script>
    <script src="../_static/js/jquery-1.11.0.min.js"></script>
    <script src="../_static/js/jquery-fix.js"></script>
    <script src="../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script src="../_static/bootstrap-sphinx.js"></script>
    <link rel="icon" href="../_static/favicon.png"/>
    <link rel="author" title="About these documents" href="../about.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Deploying Pangeo in the Cloud" href="cloud.html" />
    <link rel="prev" title="Deployment Setup Guides" href="index.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head><body>

  <div id="navbar" class="navbar navbar-inverse navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
            <span><img src="../_static/small_e_reversed_24px.png"></span>
          Pangeo</a>
        <span class="navbar-text navbar-version pull-left"><b></b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="https://medium.com/pangeo">Blog</a></li>
                <li><a href="https://discourse.pangeo.io">Forum</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../about.html">About Pangeo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../about.html#motivation">Motivation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about.html#mission-statement">Mission Statement</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about.html#goals">Goals</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about.html#get-involved">Get Involved</a></li>
<li class="toctree-l2"><a class="reference internal" href="../about.html#governance">Governance</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Guide for Scientists</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../quickstart.html#learn-about-pangeo-software">Learn About Pangeo Software</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart.html#explore-the-use-cases">Explore the Use Cases</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart.html#try-out-a-pangeo-environment">Try Out a Pangeo Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart.html#give-feedback">Give Feedback</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart.html#contribute-a-use-case">Contribute a Use Case</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart.html#contribute-data">Contribute Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../quickstart.html#become-an-open-source-contributor">Become an Open Source Contributor</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../packages.html">Packages</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../packages.html#pangeo-core-packages">Pangeo Core Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages.html#pangeo-affiliated-packages">Pangeo Affiliated Packages</a></li>
<li class="toctree-l2"><a class="reference internal" href="../packages.html#guidelines-for-new-packages">Guidelines for New Packages</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../gallery.html">Pangeo Gallery</a></li>
<li class="toctree-l1"><a class="reference internal" href="../architecture.html">Technical Architecture</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../architecture.html#where-we-began">Where we began</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture.html#interoperability-in-pangeo">Interoperability in Pangeo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture.html#software">Software</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture.html#compute-platforms">Compute Platforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../architecture.html#storage-formats">Storage Formats</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Deployment Setup Guides</a><ul class="current">
<li class="toctree-l2 current"><a class="reference internal" href="index.html#setting-up-pangeo-on-hpc-systems">Setting up Pangeo on HPC Systems</a></li>
<li class="toctree-l2"><a class="reference internal" href="index.html#setting-up-pangeo-on-cloud-systems">Setting up Pangeo on Cloud Systems</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../cloud.html">Pangeo Cloud</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../cloud.html#operated-by-2i2c">Operated by 2i2c</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cloud.html#quickstart">Quickstart</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cloud.html#getting-support">Getting Support</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cloud.html#sign-up">Sign Up</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cloud.html#hubs">Hubs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cloud.html#software-environment">Software Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cloud.html#hardware-environment">Hardware Environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cloud.html#files-and-data-in-the-cloud">Files and Data in the Cloud</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cloud.html#dask">Dask</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../data.html">Pangeo and Data</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../data.html#data-on-hpc">Data on HPC</a></li>
<li class="toctree-l2"><a class="reference internal" href="../data.html#data-in-the-cloud">Data in the Cloud</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../catalog.html">Pangeo Data Catalog</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collaborators.html">Funders and Collaborators</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../collaborators.html#funding-agencies">Funding Agencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../collaborators.html#institutions">Institutions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../collaborators.html#people">People</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../publications.html">Publications</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../publications.html#self-reported">Self-Reported</a></li>
<li class="toctree-l2"><a class="reference internal" href="../publications.html#reporting-form">Reporting Form</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../pangeo-showcase.html">Pangeo Showcase</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../pangeo-showcase.html#winter-spring-2024-showcase">Winter/Spring 2024 Showcase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pangeo-showcase.html#fall-2023-showcase">Fall 2023 Showcase</a></li>
<li class="toctree-l2"><a class="reference internal" href="../pangeo-showcase.html#showcase-archive">Showcase Archive</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../meeting-notes.html">Meeting Schedule and Notes</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../meeting-notes.html#community-meeting">Community Meeting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../meeting-notes.html#continental-community-meetings">Continental Community Meetings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../meeting-notes.html#working-group-meetings">Working Group Meetings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../meeting-notes.html#meetings-calendar">Meetings Calendar</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../meetings/index.html">Pangeo Conferences</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../meetings/index.html#past-meetings">Past Meetings</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../roadmap.html">Pangeo Roadmap</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../roadmap.html#supporting-the-pangeo-community">Supporting the Pangeo Community</a></li>
<li class="toctree-l2"><a class="reference internal" href="../roadmap.html#supporting-the-evoloution-of-the-geoscience-software-stack">Supporting the Evoloution of the Geoscience Software Stack</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../contact.html">Contact Pangeo</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../contact.html#discourse">Discourse</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contact.html#github">Github</a></li>
<li class="toctree-l2"><a class="reference internal" href="../contact.html#other-media">Other Media</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
                <li class="dropdown">
  <a role="button"
     id="dLabelLocalToc"
     data-toggle="dropdown"
     data-target="#"
     href="#">Page <b class="caret"></b></a>
  <ul class="dropdown-menu localtoc"
      role="menu"
      aria-labelledby="dLabelLocalToc"><ul>
<li><a class="reference internal" href="#">Getting Started with Pangeo on HPC</a><ul>
<li><a class="reference internal" href="#installing-a-software-environment">Installing a software environment</a></li>
<li><a class="reference internal" href="#configure-jupyter">Configure Jupyter</a></li>
<li><a class="reference internal" href="#deploy-option-1-jupyter-dask-jobqueue">Deploy Option 1: Jupyter + dask-jobqueue</a><ul>
<li><a class="reference internal" href="#start-a-jupyter-notebook-server">Start a Jupyter Notebook Server</a></li>
<li><a class="reference internal" href="#launch-dask-with-dask-jobqueue">Launch Dask with dask-jobqueue</a></li>
</ul>
</li>
<li><a class="reference internal" href="#deploy-option-2-jupyter-dask-mpi">Deploy Option 2: Jupyter + dask-mpi</a><ul>
<li><a class="reference internal" href="#launch-and-connect-to-jupyter">Launch and connect to Jupyter</a></li>
</ul>
</li>
<li><a class="reference internal" href="#further-reading">Further Reading</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
              
                
  <li>
    <a href="index.html" title="Previous Chapter: Deployment Setup Guides"><span class="glyphicon glyphicon-chevron-left visible-sm"></span><span class="hidden-sm hidden-tablet">&laquo; Deployment Se...</span>
    </a>
  </li>
  <li>
    <a href="cloud.html" title="Next Chapter: Deploying Pangeo in the Cloud"><span class="glyphicon glyphicon-chevron-right visible-sm"></span><span class="hidden-sm hidden-tablet">Deploying Pan... &raquo;</span>
    </a>
  </li>
              
            
            
            
            
          </ul>

          
            
            
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Getting Started with Pangeo on HPC</a><ul>
<li><a class="reference internal" href="#installing-a-software-environment">Installing a software environment</a></li>
<li><a class="reference internal" href="#configure-jupyter">Configure Jupyter</a></li>
<li><a class="reference internal" href="#deploy-option-1-jupyter-dask-jobqueue">Deploy Option 1: Jupyter + dask-jobqueue</a><ul>
<li><a class="reference internal" href="#start-a-jupyter-notebook-server">Start a Jupyter Notebook Server</a></li>
<li><a class="reference internal" href="#launch-dask-with-dask-jobqueue">Launch Dask with dask-jobqueue</a></li>
</ul>
</li>
<li><a class="reference internal" href="#deploy-option-2-jupyter-dask-mpi">Deploy Option 2: Jupyter + dask-mpi</a><ul>
<li><a class="reference internal" href="#launch-and-connect-to-jupyter">Launch and connect to Jupyter</a></li>
</ul>
</li>
<li><a class="reference internal" href="#further-reading">Further Reading</a></li>
</ul>
</li>
</ul>

<div class="widget navlinks">
  <ul class="this-page-menu">
    <li><a href="https://github.com/pangeo-data/pangeo/blob/master/docs/setup_guides/hpc.rst"
            rel="nofollow"
            target="_blank"><span class="fa-stack fa-md"><i class="fa fa-github fa-stack-1x"></i></span> Edit on GitHub</a></li>
  </ul>
</div>
        </div>
      </div>
    <div class="col-md-9 content ">
      
  <section id="getting-started-with-pangeo-on-hpc">
<span id="hpc"></span><h1>Getting Started with Pangeo on HPC<a class="headerlink" href="#getting-started-with-pangeo-on-hpc" title="Link to this heading">¶</a></h1>
<p>This tutorial covers how to set up an environment to run Pangeo on High
Performance Computing (HPC) systems. In particular it covers the following:</p>
<ol class="arabic simple">
<li><p>Install <a class="reference external" href="https://conda.io/docs/">conda</a> and creating an environment</p></li>
<li><p>Configure <a class="reference external" href="https://jupyter.org/">Jupyter</a></p></li>
<li><p>Launch <a class="reference external" href="https://dask.pydata.org/">Dask</a> with a job scheduler</p></li>
<li><p>Launch a <a class="reference external" href="https://jupyter.org/">Jupyter</a> server for your job</p></li>
<li><p>Connect to <a class="reference external" href="https://jupyter.org/">Jupyter</a> and the <a class="reference external" href="https://dask.pydata.org/">Dask</a> dashboard from your personal computer</p></li>
</ol>
<p>Although the examples on this page were developed using NCAR’s <a class="reference external" href="https://www2.cisl.ucar.edu/resources/computational-systems/cheyenne">Cheyenne</a> super
computer, the concepts here should be generally applicable to typical HPC systems.
This document assumes that you already have an access to an HPC like Cheyenne,
and are comfortable using the command line. It may be necessary to work with your
system administrators to properly configure these tools for your machine.</p>
<p>You should log into your HPC system now.</p>
<section id="installing-a-software-environment">
<h2>Installing a software environment<a class="headerlink" href="#installing-a-software-environment" title="Link to this heading">¶</a></h2>
<p>After you have logged into your HPC system, download and install Miniforge:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>url=https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-Linux-x86_64.sh
curl -k -L $url -o Miniforge.sh
sh Miniforge.sh
export PATH=$HOME/Miniforge3/bin:$PATH
</pre></div>
</div>
<p>This contains a self-contained Python environment that we can manipulate
safely without requiring the involvement of IT. It also allows you to
create isolated software environments so that we can experiment in the
future safely.</p>
<p>Before creating your environment, update your conda package manager with packages
from the conda-forge channel instead of the default channel and install Mamba,
which works like conda but is written in C++ and therefore creates environments faster.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">config</span> <span class="o">--</span><span class="n">add</span> <span class="n">channels</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> <span class="o">--</span><span class="n">force</span>
<span class="n">conda</span> <span class="n">config</span> <span class="o">--</span><span class="n">remove</span> <span class="n">channels</span> <span class="n">defaults</span> <span class="o">--</span><span class="n">force</span>
<span class="n">conda</span> <span class="n">install</span> <span class="n">mamba</span> <span class="o">-</span><span class="n">y</span>
<span class="n">mamba</span> <span class="n">update</span> <span class="o">--</span><span class="nb">all</span>
</pre></div>
</div>
<p>Depending if you chose to initialize Miniforge in your <code class="docutils literal notranslate"><span class="pre">~/.bashrc</span></code>
at the end of the installation, this new conda update will activate
a <code class="docutils literal notranslate"><span class="pre">(base)</span></code> environment by default. If you wish to prevent conda
from activating the <code class="docutils literal notranslate"><span class="pre">(base)</span></code> environment at shell initialization:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">config</span> <span class="o">--</span><span class="nb">set</span> <span class="n">auto_activate_base</span> <span class="n">false</span>
</pre></div>
</div>
<p>This will create a <code class="docutils literal notranslate"><span class="pre">./condarc</span></code> in your home
directory with this setting the first time you run it.</p>
<p>Create a new conda environment for our pangeo work:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mamba</span> <span class="n">create</span> <span class="o">-</span><span class="n">n</span> <span class="n">pangeo</span> <span class="o">-</span><span class="n">c</span> <span class="n">conda</span><span class="o">-</span><span class="n">forge</span> \
    <span class="n">python</span> <span class="n">dask</span> <span class="n">jupyterlab</span> <span class="n">dask</span><span class="o">-</span><span class="n">jobqueue</span> <span class="n">ipywidgets</span> \
    <span class="n">xarray</span> <span class="n">zarr</span> <span class="n">numcodecs</span> <span class="n">hvplot</span> <span class="n">geoviews</span> <span class="n">datashader</span>  \
    <span class="n">jupyter</span><span class="o">-</span><span class="n">server</span><span class="o">-</span><span class="n">proxy</span> <span class="n">widgetsnbextension</span> <span class="n">dask</span><span class="o">-</span><span class="n">labextension</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Depending on your application, you may choose to add additional conda
packages to this list.</p>
</div>
<p>Activate this environment (and note that with Jupyterlab version 3, extensions no longer need to be added after environment creation):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">activate</span> <span class="n">pangeo</span>
</pre></div>
</div>
<p>Your prompt should now look something like this (note the pangeo environment name):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pangeo) $
</pre></div>
</div>
<p>And if you ask where your Python command lives, it should direct you to
somewhere in your home directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pangeo) $ which python
$HOME/Miniforge3/envs/pangeo/bin/python
</pre></div>
</div>
</section>
<section id="configure-jupyter">
<h2>Configure Jupyter<a class="headerlink" href="#configure-jupyter" title="Link to this heading">¶</a></h2>
<p>(If you don’t plan to use Jupyter notebooks then you can safely skip
this section.)</p>
<p>Jupyter notebook servers include a password for security. First we generate the Jupyter config
file then set a password:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">jupyter</span> <span class="n">server</span> <span class="o">--</span><span class="n">generate</span><span class="o">-</span><span class="n">config</span>
<span class="n">jupyter</span> <span class="n">server</span> <span class="n">password</span>
</pre></div>
</div>
<p>This created a file in <code class="docutils literal notranslate"><span class="pre">~/.jupyter/jupyter_server_config.py</span></code>.
For security reasons, we recommend making sure your <code class="docutils literal notranslate"><span class="pre">jupyter_server_config.py</span></code>
is readable only by you. For more information on this and other methods for
securing Jupyter, check out
<a class="reference external" href="http://jupyter-notebook.readthedocs.io/en/stable/public_server.html#securing-a-notebook-server">Securing a notebook server</a>
in the Jupyter documentation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">chmod</span> <span class="mi">400</span> <span class="o">~/.</span><span class="n">jupyter</span><span class="o">/</span><span class="n">jupyter_server_config</span><span class="o">.</span><span class="n">py</span>
</pre></div>
</div>
<p>Finally, we may want to configure dask’s dashboard to forward through Jupyter.</p>
<p>Add this to your <code class="docutils literal notranslate"><span class="pre">~/.bashrc</span></code> file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">export</span> <span class="n">DASK_DISTRIBUTED__DASHBOARD__LINK</span><span class="o">=</span><span class="s2">&quot;/proxy/8787/status&quot;</span>
</pre></div>
</div>
<hr class="docutils" />
<p>From here, we have two options. Option 1 will start a Jupyter Notebook server
and manage dask using the <a class="reference external" href="http://dask-jobqueue.readthedocs.io">dask-jobqueue</a> package. Option 2 will start a dask
cluster using <cite>dask-mpi</cite> and will run a Jupyter server as part of the dask cluster.
We generally recommend starting with Option 1, especially if you will be working
interactively, unless you have a reason for managing the job submission scripts
on your own. Users that will be using dask in batch-style workflows may prefer
Option 2.</p>
</section>
<section id="deploy-option-1-jupyter-dask-jobqueue">
<h2>Deploy Option 1: Jupyter + dask-jobqueue<a class="headerlink" href="#deploy-option-1-jupyter-dask-jobqueue" title="Link to this heading">¶</a></h2>
<section id="start-a-jupyter-notebook-server">
<h3>Start a Jupyter Notebook Server<a class="headerlink" href="#start-a-jupyter-notebook-server" title="Link to this heading">¶</a></h3>
<p>Now that we have Jupyter configured, we can start a notebook server. In many
cases, your system administrators will want you to run this notebook server in
an interactive session on a compute node. This is not universal rule, but it is
one we’ll follow for this tutorial.</p>
<p>In our case, the Cheyenne super computer uses the PBS job scheduler, so typing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pangeo) $ qsub -I -A account -l select=1:ncpus=4 -l walltime=03:00:00 -q regular
</pre></div>
</div>
<p>This will get us an interactive job on the <cite>regular</cite> queue for three hours. You
may not see the <cite>pangeo</cite> environment anymore in your prompt, in this case, you
will want to reactivate it.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">conda</span> <span class="n">activate</span> <span class="n">pangeo</span>
</pre></div>
</div>
<p>From here, we can start jupyter. The Cheyenne computer administrators have
developed a <a class="reference external" href="https://www2.cisl.ucar.edu/resources/computational-systems/cheyenne/software/jupyter-and-ipython#notebook">start-notebook</a>
utility that wraps the following steps into a single execution. You should
check with your system administrators to see if they have something similar.</p>
<p>If not, you can easily create your own start_jupyter script.  In the script below, we choose a random port
on the server (to reduce the chance of conflict with another user), but we use port 8889 on the client, as port 8888 is
the default client port if you are running Jupyter locally.  We can also change to a starting directory:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pangeo) $ more ~/bin/start_jupyter
cd /home/data/username
JPORT=$(shuf -i 8400-9400 -n 1)
echo &quot;&quot;
echo &quot;&quot;
echo &quot;Step 1: Wait until this script says the Jupyter server&quot;
echo &quot;        has started. &quot;
echo &quot;&quot;
echo &quot;Step 2: Copy this ssh command into a terminal on your&quot;
echo &quot;        local computer:&quot;
echo &quot;&quot;
echo &quot;        ssh -N -L 8889:`hostname`:$JPORT $USER@my-hpc-cluster.edu&quot;
echo &quot;&quot;
echo &quot;Step 3: Browse to http://localhost:8889 on your local computer&quot;
echo &quot;&quot;
echo &quot;&quot;
sleep 2
jupyter lab --no-browser --ip=`hostname` --port=$JPORT
</pre></div>
</div>
<p>Now we can launch the Jupyter server:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>(pangeo) $ ~/bin/start_jupyter

Step 1:...
Step 2:...
Step 3:...
...

[I 2021-04-06 06:33:57.962 ServerApp] Jupyter Server 1.5.1 is running at:
[I 2021-04-06 06:33:57.962 ServerApp] http://pn009:8537/lab
[I 2021-04-06 06:33:57.963 ServerApp]  or http://127.0.0.1:8537/lab
[I 2021-04-06 06:33:57.963 ServerApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).
</pre></div>
</div>
<p>Just follow the Steps 1,2,3 printed out by the script to get connected.</p>
</section>
<section id="launch-dask-with-dask-jobqueue">
<h3>Launch Dask with dask-jobqueue<a class="headerlink" href="#launch-dask-with-dask-jobqueue" title="Link to this heading">¶</a></h3>
<p>Most HPC systems use a job-scheduling system to manage job submissions and
executions among many users. The <a class="reference external" href="http://dask-jobqueue.readthedocs.io">dask-jobqueue</a> package is designed to help
dask interface with these job queuing systems. Usage is quite simple and can be
done from within your Jupyter Notebook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dask_jobqueue</span> <span class="kn">import</span> <span class="n">PBSCluster</span>

<span class="n">cluster</span> <span class="o">=</span> <span class="n">PBSCluster</span><span class="p">(</span><span class="n">cores</span><span class="o">=</span><span class="mi">36</span><span class="p">,</span>
                     <span class="n">processes</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">memory</span><span class="o">=</span><span class="s2">&quot;6GB&quot;</span><span class="p">,</span>
                     <span class="n">project</span><span class="o">=</span><span class="s1">&#39;UCLB0022&#39;</span><span class="p">,</span>
                     <span class="n">queue</span><span class="o">=</span><span class="s1">&#39;premium&#39;</span><span class="p">,</span>
                     <span class="n">resource_spec</span><span class="o">=</span><span class="s1">&#39;select=1:ncpus=36:mem=109G&#39;</span><span class="p">,</span>
                     <span class="n">walltime</span><span class="o">=</span><span class="s1">&#39;02:00:00&#39;</span><span class="p">)</span>
<span class="n">cluster</span><span class="o">.</span><span class="n">scale</span><span class="p">(</span><span class="mi">18</span><span class="p">)</span>

<span class="kn">from</span> <span class="nn">dask.distributed</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">cluster</span><span class="p">)</span>
</pre></div>
</div>
<p>The <cite>scale()</cite> method submits a batch of jobs to the job queue system
(in this case PBS). Depending on how busy the job queue is, it can take a few
minutes for workers to join your cluster. You can usually check the status of
your queued jobs using a command line utility like <cite>qstat</cite>. You can also check
the status of your cluster from inside your Jupyter session:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">client</span><span class="p">)</span>
</pre></div>
</div>
<p>For more examples of how to use
<a class="reference external" href="http://dask-jobqueue.readthedocs.io">dask-jobqueue</a>, refer to the
<a class="reference external" href="http://dask-jobqueue.readthedocs.io">package documentation</a>.</p>
</section>
</section>
<section id="deploy-option-2-jupyter-dask-mpi">
<h2>Deploy Option 2: Jupyter + dask-mpi<a class="headerlink" href="#deploy-option-2-jupyter-dask-mpi" title="Link to this heading">¶</a></h2>
<p>This approach allows you to deploy dask directly using batch jobs on your HPC
machine.</p>
<p>The MPI library is only used to distribute the dask-workers across the
cluster. MPI is <strong>NOT</strong> used for communication by dask.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The following scripts and procedures have been packed into a convenient wrapper
script <code class="docutils literal notranslate"><span class="pre">launch-dask.sh</span></code>. It and its supporting utilities can be found in the
<a class="reference external" href="https://github.com/pangeo-data/pangeo/tree/master/utilities/cheyenne">pangeo Github repository</a>.</p>
<p>The usage of this script is quite simple:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>./launch-dask.sh<span class="w"> </span><span class="si">${</span><span class="nv">N_WORK_NODES</span><span class="si">}</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">N_WORK_NODES</span></code> is the number of nodes you want to add to the cluster
beyond the one that is automatically added for the scheduler. Once this command
has been run, and after a moment for the jobs to work their way through the queue,
it will print something like:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>Run<span class="w"> </span>the<span class="w"> </span>following<span class="w"> </span><span class="nb">command</span><span class="w"> </span>from<span class="w"> </span>your<span class="w"> </span><span class="nb">local</span><span class="w"> </span>machine:
ssh<span class="w"> </span>-N<span class="w"> </span>-L<span class="w"> </span><span class="m">8888</span>:r7i3n13:8888<span class="w">  </span>username@cheyenne.ucar.edu
Then<span class="w"> </span>open<span class="w"> </span>the<span class="w"> </span>following<span class="w"> </span>URLs:
<span class="w">    </span>Jupyter<span class="w"> </span>lab:<span class="w"> </span>http://localhost:8888
<span class="w">    </span>Dask<span class="w"> </span>dashboard:<span class="w"> </span>http://localhost:8888/proxy/8787
</pre></div>
</div>
<p>It may be necessary to modify the included scripts to use different PBS
project number, conda environment, or notebook directory.</p>
</div>
<p><em>The remainder of this section is left here for completeness but for most users,
the ``launch-dask.sh`` script should be enough to get started.</em></p>
<hr class="docutils" />
<p>Copy and paste the following text into a file, dask.sh:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span><span class="ch">#!/bin/bash</span>
<span class="c1">#PBS -N sample</span>
<span class="c1">#PBS -q economy</span>
<span class="c1">#PBS -A UCLB0022</span>
<span class="c1">#PBS -l select=2:ncpus=36:mpiprocs=6</span>
<span class="c1">#PBS -l walltime=01:00:00</span>
<span class="c1">#PBS -j oe</span>
<span class="c1">#PBS -m abe</span>

<span class="c1"># Qsub template for UCAR CHEYENNE</span>
<span class="c1"># Scheduler: PBS</span>

<span class="c1"># This writes a scheduler.json file into your home directory</span>
<span class="c1"># You can then connect with the following Python code</span>
<span class="c1"># &gt;&gt;&gt; from dask.distributed import Client</span>
<span class="c1"># &gt;&gt;&gt; client = Client(scheduler_file=&#39;~/scheduler.json&#39;)</span>

rm<span class="w"> </span>-f<span class="w"> </span>scheduler.json
mpirun<span class="w"> </span>--np<span class="w"> </span><span class="m">12</span><span class="w"> </span>dask-mpi<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--nthreads<span class="w"> </span><span class="m">6</span><span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--memory-limit<span class="w"> </span>24e9<span class="w"> </span><span class="se">\</span>
<span class="w">    </span>--interface<span class="w"> </span>ib0
</pre></div>
</div>
<p>This script asks for two nodes with 36 cores each. It breaks up each
node into 6 MPI processes, each of which gets 6 cores and 24GB of RAM
each. You can tweak the numbers above if you like, but you’ll have to
match some constraints in the PBS directives on the top and the
<code class="docutils literal notranslate"><span class="pre">mpirun</span></code> keywords on the bottom.</p>
<p>Submit this script to run on the cluster with <code class="docutils literal notranslate"><span class="pre">qsub</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">qsub</span> <span class="n">dask</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>And track its progress with <code class="docutils literal notranslate"><span class="pre">qstat</span></code></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ qstat -u $USER

chadmin1:
                                                            Req&#39;d  Req&#39;d   Elap
Job ID          Username Queue    Jobname    SessID NDS TSK Memory Time  S Time
--------------- -------- -------- ---------- ------ --- --- ------ ----- - -----
1681778.chadmin username regular  sample      27872   2 144    --  00:20 R 00:01
</pre></div>
</div>
<p>When this job runs it places a <code class="docutils literal notranslate"><span class="pre">scheduler.json</span></code> file in your home
directory. This contains the necessary information to connect to this
cluster from anywhere in the network. We’ll do that now briefly from the
login node. In the next section we’ll set up a Jupyter notebook server
on your allocation.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ ipython
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dask.distributed</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">scheduler_file</span><span class="o">=</span><span class="s1">&#39;scheduler.json&#39;</span><span class="p">)</span>
<span class="n">client</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">Out</span><span class="p">[</span><span class="mi">3</span><span class="p">]:</span> <span class="o">&lt;</span><span class="n">Client</span><span class="p">:</span> <span class="n">scheduler</span><span class="o">=</span><span class="s1">&#39;tcp://10.148.0.92:8786&#39;</span> <span class="n">processes</span><span class="o">=</span><span class="mi">11</span> <span class="n">cores</span><span class="o">=</span><span class="mi">66</span><span class="o">&gt;</span>
</pre></div>
</div>
<section id="launch-and-connect-to-jupyter">
<h3>Launch and connect to Jupyter<a class="headerlink" href="#launch-and-connect-to-jupyter" title="Link to this heading">¶</a></h3>
<p>From your same session on the login node, run the following code:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">dask.distributed</span> <span class="kn">import</span> <span class="n">Client</span>
<span class="n">client</span> <span class="o">=</span> <span class="n">Client</span><span class="p">(</span><span class="n">scheduler_file</span><span class="o">=</span><span class="s1">&#39;scheduler.json&#39;</span><span class="p">)</span>

<span class="kn">import</span> <span class="nn">socket</span>
<span class="n">host</span> <span class="o">=</span> <span class="n">client</span><span class="o">.</span><span class="n">run_on_scheduler</span><span class="p">(</span><span class="n">socket</span><span class="o">.</span><span class="n">gethostname</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">start_jlab</span><span class="p">(</span><span class="n">dask_scheduler</span><span class="p">):</span>
    <span class="kn">import</span> <span class="nn">subprocess</span>
    <span class="n">proc</span> <span class="o">=</span> <span class="n">subprocess</span><span class="o">.</span><span class="n">Popen</span><span class="p">([</span><span class="s1">&#39;jupyter&#39;</span><span class="p">,</span> <span class="s1">&#39;lab&#39;</span><span class="p">,</span> <span class="s1">&#39;--ip&#39;</span><span class="p">,</span> <span class="n">host</span><span class="p">,</span> <span class="s1">&#39;--no-browser&#39;</span><span class="p">])</span>
    <span class="n">dask_scheduler</span><span class="o">.</span><span class="n">jlab_proc</span> <span class="o">=</span> <span class="n">proc</span>

<span class="n">client</span><span class="o">.</span><span class="n">run_on_scheduler</span><span class="p">(</span><span class="n">start_jlab</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ssh -N -L 8888:</span><span class="si">%s</span><span class="s2">:8888 cheyenne.ucar.edu&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">host</span><span class="p">))</span>
</pre></div>
</div>
<p>This should print out a statement like the following:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">ssh</span> <span class="o">-</span><span class="n">N</span> <span class="o">-</span><span class="n">L</span> <span class="mi">8888</span><span class="p">:</span><span class="n">r13i2n1</span><span class="p">:</span><span class="mi">8888</span> <span class="o">-</span><span class="n">l</span> <span class="n">username</span> <span class="n">cheyenne</span><span class="o">.</span><span class="n">ucar</span><span class="o">.</span><span class="n">edu</span>
</pre></div>
</div>
<p>You can run this command from your personal computer (not the terminal
logged into Cheyenne) to set up SSH-tunnels that will allow you to log
into web servers running on your allocation. Afterwards, you should be
able to open the following links in your web browser on your computer:</p>
<ul class="simple">
<li><p>Jupyter Lab: <a class="reference external" href="http://localhost:8888">http://localhost:8888</a></p></li>
<li><p>Dask dashboard: <a class="reference external" href="http://localhost:8888/proxy/8787/status">http://localhost:8888/proxy/8787/status</a></p></li>
</ul>
<p>The SSH tunnels will route these into the correct machine in your
cluster allocation.</p>
<p><strong>Dynamic Deployment</strong></p>
<p>The job scheduler that manages the cluster is not intended for
interactive work like what we do with Jupyter notebooks. When we ask for
a modestly large deployment (like five machines) it may wait for hours
to find an appropriate time slot to deploy our job. This can be
inconvenient because our human schedules may not match up well with the
cluster’s job scheduler.</p>
<p>However we seem to be able to get much faster response from the job
scheduler if we launch many single-machine jobs. This allows us to get
larger allocations faster (often immediately).</p>
<p>We can do this by making our deployment process a little bit more
complex by splitting it into two jobs:</p>
<ol class="arabic simple">
<li><p>One job that launches a scheduler and a few workers on one machine</p></li>
<li><p>Another job that only launches workers on one machine</p></li>
</ol>
<p>Write these two scripts to your home directory:</p>
<p><strong>Main script</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#PBS -N dask
#PBS -q economy
#PBS -A UCLB0022
#PBS -l select=1:ncpus=36:mpiprocs=6
#PBS -l walltime=00:30:00
#PBS -j oe
#PBS -m abe

# Writes ~/scheduler.json file in home directory
# Connect with
# &gt;&gt;&gt; from dask.distributed import Client
# &gt;&gt;&gt; client = Client(scheduler_file=&#39;~/scheduler.json&#39;)

rm -f scheduler.json
mpirun --np 6 dask-mpi --nthreads 6 \
    --memory-limit 22e9 \
    --interface ib0 \
    --local-directory $TMPDIR
</pre></div>
</div>
<p><strong>Add one worker script</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>#!/bin/bash
#PBS -N dask-workers
#PBS -q economy
#PBS -A UCLB0022
#PBS -l select=1:ncpus=36:mpiprocs=6
#PBS -l walltime=00:30:00
#PBS -j oe
#PBS -m abe

mpirun --np 6 dask-mpi --nthreads 6 \
    --memory-limit 22e9 \
    --interface ib0 \
    --no-scheduler \
    --local-directory $TMPDIR
</pre></div>
</div>
<p>And then run the main one once</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">qsub</span> <span class="n">main</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>And the second one a few times</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">qsub</span> <span class="n">add</span><span class="o">-</span><span class="n">one</span><span class="o">-</span><span class="n">worker</span><span class="o">.</span><span class="n">sh</span>
<span class="n">qsub</span> <span class="n">add</span><span class="o">-</span><span class="n">one</span><span class="o">-</span><span class="n">worker</span><span class="o">.</span><span class="n">sh</span>
<span class="n">qsub</span> <span class="n">add</span><span class="o">-</span><span class="n">one</span><span class="o">-</span><span class="n">worker</span><span class="o">.</span><span class="n">sh</span>
<span class="n">qsub</span> <span class="n">add</span><span class="o">-</span><span class="n">one</span><span class="o">-</span><span class="n">worker</span><span class="o">.</span><span class="n">sh</span>
</pre></div>
</div>
<p>You can run this more times during your session to increase your
allocation dynamically. You can also kill these jobs independently to
contract your allocation dynamically and save compute time.</p>
</section>
</section>
<section id="further-reading">
<h2>Further Reading<a class="headerlink" href="#further-reading" title="Link to this heading">¶</a></h2>
<p>We have not attempted to provide a comprehensive tutorial on how to use Pangeo,
Dask, or Jupyter on HPC systems. This is because each HPC system is uniquely
configured. Instead we have provided two generalizable workflows for deploying
Pangeo. Below we provide a few useful links that will be useful for further
customization of these tools.</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="http://dask.pydata.org/en/latest/setup/hpc.html">Deploying Dask on HPC</a></p></li>
<li><p><a class="reference external" href="http://jupyter-notebook.readthedocs.io/en/stable/index.html">Configuring and Deploying Jupyter Servers</a></p></li>
</ul>
</div></blockquote>
</section>
</section>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright 2018-2023, Pangeo Team.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 7.2.6.<br/>
    </p>
  </div>
</footer>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-4K4N4RYC53"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-4K4N4RYC53');
</script>
  </body>
</html>